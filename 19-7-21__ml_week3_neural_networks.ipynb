{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "file = 'wisconsin.csv'\n",
    "path_to_file = path+file\n",
    "\n",
    "\n",
    "df = pd.read_csv(path_to_file, sep=',')\n",
    "\n",
    "# all features\n",
    "all_features = ['radius_mean','texture_mean','perimeter_mean', 'area_mean', 'smoothness_mean', \n",
    "            'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "            'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "            'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se','fractal_dimension_se', 'radius_worst', \n",
    "            'texture_worst', 'perimeter_worst','area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "            'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "\n",
    "# top 10 features as determined by recursive feature elimination from week 2 notebook\n",
    "top_10_features = ['compactness_mean', 'concave points_mean', 'radius_se', 'area_se', 'symmetry_se', 'radius_worst', 'texture_worst', 'area_worst', 'concavity_worst', 'symmetry_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(df[top_10_features])\n",
    "y_labels = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "for ind in y_labels:\n",
    "    if ind == 'M':\n",
    "        y.append(1)\n",
    "    elif ind == 'B':\n",
    "        y.append(0)\n",
    "y = np.array(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a very simple model with 1 hidden layer of 10 neurons, we will use relu activation functions, and make a binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/15\n",
      "455/455 [==============================] - 0s 903us/sample - loss: 0.5906 - acc: 0.7297 - val_loss: 0.4859 - val_acc: 0.8158\n",
      "Epoch 2/15\n",
      "455/455 [==============================] - 0s 102us/sample - loss: 0.5148 - acc: 0.8110 - val_loss: 0.4311 - val_acc: 0.8509\n",
      "Epoch 3/15\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.4542 - acc: 0.8637 - val_loss: 0.3858 - val_acc: 0.8684\n",
      "Epoch 4/15\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 0.4054 - acc: 0.8879 - val_loss: 0.3488 - val_acc: 0.9211\n",
      "Epoch 5/15\n",
      "455/455 [==============================] - 0s 70us/sample - loss: 0.3667 - acc: 0.8879 - val_loss: 0.3186 - val_acc: 0.9211\n",
      "Epoch 6/15\n",
      "455/455 [==============================] - 0s 86us/sample - loss: 0.3346 - acc: 0.8989 - val_loss: 0.2925 - val_acc: 0.9211\n",
      "Epoch 7/15\n",
      "455/455 [==============================] - 0s 127us/sample - loss: 0.3075 - acc: 0.9121 - val_loss: 0.2706 - val_acc: 0.9298\n",
      "Epoch 8/15\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 0.2851 - acc: 0.9209 - val_loss: 0.2519 - val_acc: 0.9474\n",
      "Epoch 9/15\n",
      "455/455 [==============================] - 0s 114us/sample - loss: 0.2661 - acc: 0.9253 - val_loss: 0.2361 - val_acc: 0.9474\n",
      "Epoch 10/15\n",
      "455/455 [==============================] - 0s 77us/sample - loss: 0.2493 - acc: 0.9275 - val_loss: 0.2233 - val_acc: 0.9649\n",
      "Epoch 11/15\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.2351 - acc: 0.9297 - val_loss: 0.2111 - val_acc: 0.9649\n",
      "Epoch 12/15\n",
      "455/455 [==============================] - 0s 79us/sample - loss: 0.2226 - acc: 0.9297 - val_loss: 0.2007 - val_acc: 0.9561\n",
      "Epoch 13/15\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 0.2116 - acc: 0.9297 - val_loss: 0.1910 - val_acc: 0.9561\n",
      "Epoch 14/15\n",
      "455/455 [==============================] - 0s 108us/sample - loss: 0.2019 - acc: 0.9341 - val_loss: 0.1834 - val_acc: 0.9561\n",
      "Epoch 15/15\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.1933 - acc: 0.9385 - val_loss: 0.1759 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218ccf46550>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential() #means we can add layers one at a time\n",
    "\n",
    "#add layers one at a time like lego...\n",
    "model.add(Dense(10, activation='relu')) #fully connected layer with 10 neurons\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer to output 0 or 1\n",
    "\n",
    "\n",
    "#lets the model know the loss function and the opimizer algorithm.. 'adam' is the standard optimizer\n",
    "# binary_crossentropy is the standard loss function for binary classification\n",
    "#accuracy is the score you want the model to compute\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy']) \n",
    "\n",
    "#fit the model, validation_split = cross_validation, epochs = how many times you want to run through the data\n",
    "model.fit(X, y, validation_split=0.2, epochs=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see if regularization will improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/15\n",
      "455/455 [==============================] - 0s 662us/sample - loss: 0.4451 - acc: 0.8659 - val_loss: 0.5156 - val_acc: 0.7982\n",
      "Epoch 2/15\n",
      "455/455 [==============================] - 0s 69us/sample - loss: 0.4040 - acc: 0.9099 - val_loss: 0.4690 - val_acc: 0.8246\n",
      "Epoch 3/15\n",
      "455/455 [==============================] - 0s 81us/sample - loss: 0.3674 - acc: 0.9275 - val_loss: 0.4282 - val_acc: 0.8684\n",
      "Epoch 4/15\n",
      "455/455 [==============================] - 0s 68us/sample - loss: 0.3343 - acc: 0.9319 - val_loss: 0.3897 - val_acc: 0.9035\n",
      "Epoch 5/15\n",
      "455/455 [==============================] - 0s 81us/sample - loss: 0.3046 - acc: 0.9363 - val_loss: 0.3547 - val_acc: 0.9035\n",
      "Epoch 6/15\n",
      "455/455 [==============================] - 0s 79us/sample - loss: 0.2786 - acc: 0.9407 - val_loss: 0.3238 - val_acc: 0.9123\n",
      "Epoch 7/15\n",
      "455/455 [==============================] - 0s 83us/sample - loss: 0.2553 - acc: 0.9451 - val_loss: 0.2971 - val_acc: 0.9211\n",
      "Epoch 8/15\n",
      "455/455 [==============================] - 0s 79us/sample - loss: 0.2360 - acc: 0.9473 - val_loss: 0.2748 - val_acc: 0.9298\n",
      "Epoch 9/15\n",
      "455/455 [==============================] - 0s 110us/sample - loss: 0.2192 - acc: 0.9495 - val_loss: 0.2538 - val_acc: 0.9386\n",
      "Epoch 10/15\n",
      "455/455 [==============================] - 0s 83us/sample - loss: 0.2042 - acc: 0.9451 - val_loss: 0.2344 - val_acc: 0.9386\n",
      "Epoch 11/15\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.1917 - acc: 0.9451 - val_loss: 0.2189 - val_acc: 0.9561\n",
      "Epoch 12/15\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.1809 - acc: 0.9473 - val_loss: 0.2069 - val_acc: 0.9561\n",
      "Epoch 13/15\n",
      "455/455 [==============================] - 0s 110us/sample - loss: 0.1718 - acc: 0.9473 - val_loss: 0.1958 - val_acc: 0.9561\n",
      "Epoch 14/15\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.1637 - acc: 0.9473 - val_loss: 0.1858 - val_acc: 0.9561\n",
      "Epoch 15/15\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.1567 - acc: 0.9473 - val_loss: 0.1775 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218cc82dcf8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try regularization\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "regularizer = regularizers.l2(0.001) #0.01 = regeralization constant\n",
    "\n",
    "model = Sequential() #means we can add layers one at a time\n",
    "\n",
    "#add layers one at a time like lego...\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #fully connected layer with 10 neurons\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer to output 0 or 1\n",
    "\n",
    "\n",
    "#lets the model know the loss function and the opimizer algorithm.. 'adam' is the standard optimizer\n",
    "# binary_crossentropy is the standard loss function for binary classification\n",
    "#accuracy is the score you want the model to compute\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy']) \n",
    "model.fit(X, y, validation_split=0.2, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see if a second dense layer will improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/20\n",
      "455/455 [==============================] - 0s 918us/sample - loss: 0.7210 - acc: 0.6505 - val_loss: 0.6983 - val_acc: 0.7895\n",
      "Epoch 2/20\n",
      "455/455 [==============================] - 0s 99us/sample - loss: 0.6643 - acc: 0.7231 - val_loss: 0.6609 - val_acc: 0.8158\n",
      "Epoch 3/20\n",
      "455/455 [==============================] - 0s 90us/sample - loss: 0.6152 - acc: 0.7648 - val_loss: 0.6202 - val_acc: 0.8596\n",
      "Epoch 4/20\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.5651 - acc: 0.8242 - val_loss: 0.5745 - val_acc: 0.9035\n",
      "Epoch 5/20\n",
      "455/455 [==============================] - 0s 68us/sample - loss: 0.5144 - acc: 0.8747 - val_loss: 0.5262 - val_acc: 0.9386\n",
      "Epoch 6/20\n",
      "455/455 [==============================] - 0s 90us/sample - loss: 0.4627 - acc: 0.9033 - val_loss: 0.4791 - val_acc: 0.9561\n",
      "Epoch 7/20\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.4142 - acc: 0.9297 - val_loss: 0.4363 - val_acc: 0.9561\n",
      "Epoch 8/20\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.3708 - acc: 0.9429 - val_loss: 0.3927 - val_acc: 0.9561\n",
      "Epoch 9/20\n",
      "455/455 [==============================] - 0s 110us/sample - loss: 0.3309 - acc: 0.9429 - val_loss: 0.3526 - val_acc: 0.9561\n",
      "Epoch 10/20\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.2976 - acc: 0.9429 - val_loss: 0.3156 - val_acc: 0.9561\n",
      "Epoch 11/20\n",
      "455/455 [==============================] - 0s 108us/sample - loss: 0.2695 - acc: 0.9429 - val_loss: 0.2861 - val_acc: 0.9561\n",
      "Epoch 12/20\n",
      "455/455 [==============================] - 0s 123us/sample - loss: 0.2463 - acc: 0.9429 - val_loss: 0.2610 - val_acc: 0.9561\n",
      "Epoch 13/20\n",
      "455/455 [==============================] - 0s 99us/sample - loss: 0.2266 - acc: 0.9429 - val_loss: 0.2404 - val_acc: 0.9561\n",
      "Epoch 14/20\n",
      "455/455 [==============================] - 0s 119us/sample - loss: 0.2109 - acc: 0.9495 - val_loss: 0.2244 - val_acc: 0.9561\n",
      "Epoch 15/20\n",
      "455/455 [==============================] - 0s 119us/sample - loss: 0.1979 - acc: 0.9495 - val_loss: 0.2091 - val_acc: 0.9561\n",
      "Epoch 16/20\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.1867 - acc: 0.9495 - val_loss: 0.1954 - val_acc: 0.9561\n",
      "Epoch 17/20\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.1774 - acc: 0.9538 - val_loss: 0.1861 - val_acc: 0.9561\n",
      "Epoch 18/20\n",
      "455/455 [==============================] - 0s 90us/sample - loss: 0.1694 - acc: 0.9538 - val_loss: 0.1771 - val_acc: 0.9561\n",
      "Epoch 19/20\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.1624 - acc: 0.9538 - val_loss: 0.1701 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      "455/455 [==============================] - 0s 114us/sample - loss: 0.1565 - acc: 0.9538 - val_loss: 0.1633 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218cfc549b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() #means we can add layers one at a time\n",
    "\n",
    "\n",
    "regularizer = regularizers.l2(0.001) #0.01 = regeralization constant\n",
    "\n",
    "#add layers one at a time like lego...\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #fully connected layer with 10 neurons\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #add a second layer\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer to output 0 or 1\n",
    "\n",
    "\n",
    "#lets the model know the loss function and the opimizer algorithm.. 'adam' is the standard optimizer\n",
    "# binary_crossentropy is the standard loss function for binary classification\n",
    "#accuracy is the score you want the model to compute\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy']) \n",
    "model.fit(X, y, validation_split=0.2, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #lets see if changing the learning rate will improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/40\n",
      "455/455 [==============================] - 1s 2ms/sample - loss: 1.0197 - acc: 0.3538 - val_loss: 0.9079 - val_acc: 0.5877\n",
      "Epoch 2/40\n",
      "455/455 [==============================] - 0s 113us/sample - loss: 0.9005 - acc: 0.4615 - val_loss: 0.8286 - val_acc: 0.6404\n",
      "Epoch 3/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.8123 - acc: 0.5077 - val_loss: 0.7629 - val_acc: 0.6579\n",
      "Epoch 4/40\n",
      "455/455 [==============================] - 0s 103us/sample - loss: 0.7426 - acc: 0.5758 - val_loss: 0.7080 - val_acc: 0.7018\n",
      "Epoch 5/40\n",
      "455/455 [==============================] - 0s 103us/sample - loss: 0.6873 - acc: 0.6286 - val_loss: 0.6601 - val_acc: 0.7456\n",
      "Epoch 6/40\n",
      "455/455 [==============================] - 0s 130us/sample - loss: 0.6381 - acc: 0.6879 - val_loss: 0.6157 - val_acc: 0.8158\n",
      "Epoch 7/40\n",
      "455/455 [==============================] - 0s 119us/sample - loss: 0.5910 - acc: 0.7604 - val_loss: 0.5748 - val_acc: 0.8421\n",
      "Epoch 8/40\n",
      "455/455 [==============================] - 0s 114us/sample - loss: 0.5425 - acc: 0.8176 - val_loss: 0.5307 - val_acc: 0.9123\n",
      "Epoch 9/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.4888 - acc: 0.8725 - val_loss: 0.4830 - val_acc: 0.9211\n",
      "Epoch 10/40\n",
      "455/455 [==============================] - 0s 90us/sample - loss: 0.4362 - acc: 0.9055 - val_loss: 0.4404 - val_acc: 0.9298\n",
      "Epoch 11/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.3888 - acc: 0.9187 - val_loss: 0.4030 - val_acc: 0.9474\n",
      "Epoch 12/40\n",
      "455/455 [==============================] - 0s 77us/sample - loss: 0.3497 - acc: 0.9275 - val_loss: 0.3709 - val_acc: 0.9474\n",
      "Epoch 13/40\n",
      "455/455 [==============================] - 0s 112us/sample - loss: 0.3180 - acc: 0.9363 - val_loss: 0.3420 - val_acc: 0.9561\n",
      "Epoch 14/40\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.2907 - acc: 0.9341 - val_loss: 0.3171 - val_acc: 0.9561\n",
      "Epoch 15/40\n",
      "455/455 [==============================] - 0s 110us/sample - loss: 0.2683 - acc: 0.9363 - val_loss: 0.2954 - val_acc: 0.9737\n",
      "Epoch 16/40\n",
      "455/455 [==============================] - 0s 99us/sample - loss: 0.2487 - acc: 0.9429 - val_loss: 0.2756 - val_acc: 0.9737\n",
      "Epoch 17/40\n",
      "455/455 [==============================] - 0s 77us/sample - loss: 0.2321 - acc: 0.9560 - val_loss: 0.2588 - val_acc: 0.9737\n",
      "Epoch 18/40\n",
      "455/455 [==============================] - 0s 97us/sample - loss: 0.2178 - acc: 0.9582 - val_loss: 0.2437 - val_acc: 0.9737\n",
      "Epoch 19/40\n",
      "455/455 [==============================] - 0s 81us/sample - loss: 0.2058 - acc: 0.9604 - val_loss: 0.2335 - val_acc: 0.9825\n",
      "Epoch 20/40\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.1949 - acc: 0.9604 - val_loss: 0.2211 - val_acc: 0.9825\n",
      "Epoch 21/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.1851 - acc: 0.9626 - val_loss: 0.2105 - val_acc: 0.9825\n",
      "Epoch 22/40\n",
      "455/455 [==============================] - 0s 101us/sample - loss: 0.1764 - acc: 0.9670 - val_loss: 0.2006 - val_acc: 0.9825\n",
      "Epoch 23/40\n",
      "455/455 [==============================] - 0s 127us/sample - loss: 0.1686 - acc: 0.9670 - val_loss: 0.1925 - val_acc: 0.9825\n",
      "Epoch 24/40\n",
      "455/455 [==============================] - 0s 110us/sample - loss: 0.1616 - acc: 0.9692 - val_loss: 0.1849 - val_acc: 0.9825\n",
      "Epoch 25/40\n",
      "455/455 [==============================] - 0s 119us/sample - loss: 0.1555 - acc: 0.9692 - val_loss: 0.1767 - val_acc: 0.9825\n",
      "Epoch 26/40\n",
      "455/455 [==============================] - 0s 147us/sample - loss: 0.1503 - acc: 0.9692 - val_loss: 0.1706 - val_acc: 0.9825\n",
      "Epoch 27/40\n",
      "455/455 [==============================] - 0s 163us/sample - loss: 0.1448 - acc: 0.9692 - val_loss: 0.1653 - val_acc: 0.9825\n",
      "Epoch 28/40\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 0.1404 - acc: 0.9714 - val_loss: 0.1607 - val_acc: 0.9825\n",
      "Epoch 29/40\n",
      "455/455 [==============================] - 0s 132us/sample - loss: 0.1360 - acc: 0.9714 - val_loss: 0.1572 - val_acc: 0.9737\n",
      "Epoch 30/40\n",
      "455/455 [==============================] - 0s 130us/sample - loss: 0.1322 - acc: 0.9714 - val_loss: 0.1532 - val_acc: 0.9737\n",
      "Epoch 31/40\n",
      "455/455 [==============================] - 0s 103us/sample - loss: 0.1290 - acc: 0.9714 - val_loss: 0.1492 - val_acc: 0.9737\n",
      "Epoch 32/40\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.1257 - acc: 0.9714 - val_loss: 0.1464 - val_acc: 0.9737\n",
      "Epoch 33/40\n",
      "455/455 [==============================] - 0s 108us/sample - loss: 0.1231 - acc: 0.9714 - val_loss: 0.1426 - val_acc: 0.9737\n",
      "Epoch 34/40\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.1204 - acc: 0.9714 - val_loss: 0.1390 - val_acc: 0.9737\n",
      "Epoch 35/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.1182 - acc: 0.9714 - val_loss: 0.1376 - val_acc: 0.9825\n",
      "Epoch 36/40\n",
      "455/455 [==============================] - 0s 99us/sample - loss: 0.1159 - acc: 0.9714 - val_loss: 0.1343 - val_acc: 0.9825\n",
      "Epoch 37/40\n",
      "455/455 [==============================] - 0s 88us/sample - loss: 0.1141 - acc: 0.9714 - val_loss: 0.1324 - val_acc: 0.9825\n",
      "Epoch 38/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.1121 - acc: 0.9692 - val_loss: 0.1306 - val_acc: 0.9825\n",
      "Epoch 39/40\n",
      "455/455 [==============================] - 0s 105us/sample - loss: 0.1105 - acc: 0.9692 - val_loss: 0.1297 - val_acc: 0.9825\n",
      "Epoch 40/40\n",
      "455/455 [==============================] - 0s 94us/sample - loss: 0.1085 - acc: 0.9692 - val_loss: 0.1276 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218dd7a85f8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential() #means we can add layers one at a time\n",
    "\n",
    "regularizer = regularizers.l2(0.001) #0.01 = regeralization constant\n",
    "\n",
    "#add layers one at a time like lego...\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #fully connected layer with 10 neurons\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #add a second layer\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer to output 0 or 1\n",
    "\n",
    "\n",
    "#lets the model know the loss function and the opimizer algorithm.. 'adam' is the standard optimizer\n",
    "# binary_crossentropy is the standard loss function for binary classification\n",
    "#accuracy is the score you want the model to compute\n",
    "\n",
    "new_optimizer = optimizers.Adam(lr=0.001) #lets change the learning rate\n",
    "model.compile(optimizer=new_optimizer, loss='binary_crossentropy',  metrics=['accuracy']) \n",
    "\n",
    "model.fit(X, y, validation_split=0.2, epochs=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As usual, to get a truly unbiased assessment, we should save a discrete test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/30\n",
      "409/409 [==============================] - 1s 3ms/sample - loss: 0.7713 - acc: 0.3790 - val_loss: 0.7440 - val_acc: 0.4078\n",
      "Epoch 2/30\n",
      "409/409 [==============================] - 0s 96us/sample - loss: 0.7353 - acc: 0.4181 - val_loss: 0.7129 - val_acc: 0.4369\n",
      "Epoch 3/30\n",
      "409/409 [==============================] - 0s 130us/sample - loss: 0.6991 - acc: 0.5159 - val_loss: 0.6801 - val_acc: 0.4854\n",
      "Epoch 4/30\n",
      "409/409 [==============================] - 0s 93us/sample - loss: 0.6589 - acc: 0.6650 - val_loss: 0.6409 - val_acc: 0.7184\n",
      "Epoch 5/30\n",
      "409/409 [==============================] - 0s 115us/sample - loss: 0.6125 - acc: 0.8582 - val_loss: 0.5957 - val_acc: 0.8544\n",
      "Epoch 6/30\n",
      "409/409 [==============================] - 0s 120us/sample - loss: 0.5635 - acc: 0.9193 - val_loss: 0.5504 - val_acc: 0.8738\n",
      "Epoch 7/30\n",
      "409/409 [==============================] - 0s 115us/sample - loss: 0.5144 - acc: 0.9389 - val_loss: 0.5066 - val_acc: 0.8932\n",
      "Epoch 8/30\n",
      "409/409 [==============================] - 0s 95us/sample - loss: 0.4662 - acc: 0.9389 - val_loss: 0.4638 - val_acc: 0.9029\n",
      "Epoch 9/30\n",
      "409/409 [==============================] - 0s 115us/sample - loss: 0.4195 - acc: 0.9389 - val_loss: 0.4227 - val_acc: 0.9029\n",
      "Epoch 10/30\n",
      "409/409 [==============================] - 0s 120us/sample - loss: 0.3753 - acc: 0.9438 - val_loss: 0.3847 - val_acc: 0.9029\n",
      "Epoch 11/30\n",
      "409/409 [==============================] - 0s 100us/sample - loss: 0.3342 - acc: 0.9487 - val_loss: 0.3499 - val_acc: 0.9029\n",
      "Epoch 12/30\n",
      "409/409 [==============================] - 0s 122us/sample - loss: 0.2972 - acc: 0.9487 - val_loss: 0.3187 - val_acc: 0.9223\n",
      "Epoch 13/30\n",
      "409/409 [==============================] - 0s 115us/sample - loss: 0.2651 - acc: 0.9487 - val_loss: 0.2916 - val_acc: 0.9320\n",
      "Epoch 14/30\n",
      "409/409 [==============================] - 0s 90us/sample - loss: 0.2376 - acc: 0.9511 - val_loss: 0.2688 - val_acc: 0.9320\n",
      "Epoch 15/30\n",
      "409/409 [==============================] - 0s 115us/sample - loss: 0.2146 - acc: 0.9535 - val_loss: 0.2504 - val_acc: 0.9320\n",
      "Epoch 16/30\n",
      "409/409 [==============================] - 0s 125us/sample - loss: 0.1953 - acc: 0.9535 - val_loss: 0.2357 - val_acc: 0.9320\n",
      "Epoch 17/30\n",
      "409/409 [==============================] - 0s 98us/sample - loss: 0.1801 - acc: 0.9560 - val_loss: 0.2231 - val_acc: 0.9223\n",
      "Epoch 18/30\n",
      "409/409 [==============================] - 0s 110us/sample - loss: 0.1672 - acc: 0.9560 - val_loss: 0.2127 - val_acc: 0.9223\n",
      "Epoch 19/30\n",
      "409/409 [==============================] - 0s 95us/sample - loss: 0.1566 - acc: 0.9584 - val_loss: 0.2046 - val_acc: 0.9223\n",
      "Epoch 20/30\n",
      "409/409 [==============================] - 0s 122us/sample - loss: 0.1479 - acc: 0.9584 - val_loss: 0.1972 - val_acc: 0.9320\n",
      "Epoch 21/30\n",
      "409/409 [==============================] - 0s 110us/sample - loss: 0.1401 - acc: 0.9609 - val_loss: 0.1920 - val_acc: 0.9320\n",
      "Epoch 22/30\n",
      "409/409 [==============================] - 0s 88us/sample - loss: 0.1339 - acc: 0.9633 - val_loss: 0.1875 - val_acc: 0.9320\n",
      "Epoch 23/30\n",
      "409/409 [==============================] - 0s 117us/sample - loss: 0.1281 - acc: 0.9609 - val_loss: 0.1832 - val_acc: 0.9320\n",
      "Epoch 24/30\n",
      "409/409 [==============================] - 0s 120us/sample - loss: 0.1233 - acc: 0.9682 - val_loss: 0.1802 - val_acc: 0.9320\n",
      "Epoch 25/30\n",
      "409/409 [==============================] - 0s 151us/sample - loss: 0.1189 - acc: 0.9682 - val_loss: 0.1770 - val_acc: 0.9320\n",
      "Epoch 26/30\n",
      "409/409 [==============================] - 0s 161us/sample - loss: 0.1150 - acc: 0.9682 - val_loss: 0.1743 - val_acc: 0.9320\n",
      "Epoch 27/30\n",
      "409/409 [==============================] - 0s 156us/sample - loss: 0.1114 - acc: 0.9731 - val_loss: 0.1721 - val_acc: 0.9320\n",
      "Epoch 28/30\n",
      "409/409 [==============================] - 0s 147us/sample - loss: 0.1082 - acc: 0.9731 - val_loss: 0.1706 - val_acc: 0.9320\n",
      "Epoch 29/30\n",
      "409/409 [==============================] - 0s 117us/sample - loss: 0.1053 - acc: 0.9731 - val_loss: 0.1687 - val_acc: 0.9320\n",
      "Epoch 30/30\n",
      "409/409 [==============================] - 0s 137us/sample - loss: 0.1026 - acc: 0.9731 - val_loss: 0.1667 - val_acc: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218e517c748>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed(42)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['diagnosis_num'] = le.fit_transform(df['diagnosis'])\n",
    "\n",
    "X = df[top_10_features]\n",
    "y = df['diagnosis_num'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential() #means we can add layers one at a time\n",
    "\n",
    "regularizer = regularizers.l2(0.001) #0.01 = regeralization constant\n",
    "\n",
    "#add layers one at a time like lego...\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #fully connected layer with 10 neurons\n",
    "model.add(Dense(10, activation='relu', kernel_regularizer=regularizer)) #add a second layer\n",
    "model.add(Dense(1, activation='sigmoid')) #output layer to output 0 or 1\n",
    "\n",
    "\n",
    "#lets the model know the loss function and the opimizer algorithm.. 'adam' is the standard optimizer\n",
    "# binary_crossentropy is the standard loss function for binary classification\n",
    "#accuracy is the score you want the model to compute\n",
    "\n",
    "new_optimizer = optimizers.Adam(lr=0.001) #lets change the learning rate\n",
    "model.compile(optimizer=new_optimizer, loss='binary_crossentropy',  metrics=['accuracy']) \n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_y = model.predict_classes(X_test)\n",
    "accuracy_score(pred_y,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a manual gridsearch of possible neural network architectures and hyperparameters. we will use tensorboard to help visualize the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.8434 - acc: 0.3056 - val_loss: 0.8100 - val_acc: 0.4272\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.7848 - acc: 0.3936 - val_loss: 0.7599 - val_acc: 0.5728\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.7338 - acc: 0.5306 - val_loss: 0.7130 - val_acc: 0.6602\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.6874 - acc: 0.6088 - val_loss: 0.6710 - val_acc: 0.7184\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.6465 - acc: 0.7164 - val_loss: 0.6310 - val_acc: 0.7767\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.6084 - acc: 0.7824 - val_loss: 0.5944 - val_acc: 0.8155\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.5726 - acc: 0.8386 - val_loss: 0.5604 - val_acc: 0.8447\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.5393 - acc: 0.8655 - val_loss: 0.5280 - val_acc: 0.8738\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.5081 - acc: 0.9022 - val_loss: 0.4969 - val_acc: 0.8932\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.4787 - acc: 0.9144 - val_loss: 0.4680 - val_acc: 0.8932\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.4509 - acc: 0.9315 - val_loss: 0.4412 - val_acc: 0.8932\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.4246 - acc: 0.9389 - val_loss: 0.4164 - val_acc: 0.9029\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.4000 - acc: 0.9462 - val_loss: 0.3927 - val_acc: 0.9029\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.3763 - acc: 0.9462 - val_loss: 0.3709 - val_acc: 0.9223\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.3544 - acc: 0.9560 - val_loss: 0.3497 - val_acc: 0.9223\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.4082 - acc: 0.8533 - val_loss: 0.2898 - val_acc: 0.8932\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.2109 - acc: 0.9315 - val_loss: 0.1984 - val_acc: 0.9223\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.1460 - acc: 0.9487 - val_loss: 0.1688 - val_acc: 0.9320\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.1146 - acc: 0.9560 - val_loss: 0.1582 - val_acc: 0.9320\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.0953 - acc: 0.9731 - val_loss: 0.1501 - val_acc: 0.9320\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.0818 - acc: 0.9756 - val_loss: 0.1519 - val_acc: 0.9320\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.0749 - acc: 0.9804 - val_loss: 0.1500 - val_acc: 0.9320\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.0694 - acc: 0.9829 - val_loss: 0.1506 - val_acc: 0.9320\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.0669 - acc: 0.9829 - val_loss: 0.1539 - val_acc: 0.9320\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.0635 - acc: 0.9829 - val_loss: 0.1509 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.0618 - acc: 0.9853 - val_loss: 0.1495 - val_acc: 0.9417\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.0595 - acc: 0.9829 - val_loss: 0.1538 - val_acc: 0.9320\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.0578 - acc: 0.9853 - val_loss: 0.1538 - val_acc: 0.9417\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.0563 - acc: 0.9853 - val_loss: 0.1522 - val_acc: 0.9515\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.0550 - acc: 0.9853 - val_loss: 0.1517 - val_acc: 0.9417\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.7196 - acc: 0.3961 - val_loss: 0.6757 - val_acc: 0.6019\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.6848 - acc: 0.6381 - val_loss: 0.6408 - val_acc: 0.8350\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.6495 - acc: 0.7751 - val_loss: 0.6078 - val_acc: 0.8738\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.6151 - acc: 0.8460 - val_loss: 0.5729 - val_acc: 0.8835\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.5780 - acc: 0.8802 - val_loss: 0.5352 - val_acc: 0.9029\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.5369 - acc: 0.8924 - val_loss: 0.4951 - val_acc: 0.9029\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.4921 - acc: 0.9071 - val_loss: 0.4525 - val_acc: 0.9126\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.4448 - acc: 0.9071 - val_loss: 0.4090 - val_acc: 0.9223\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.3976 - acc: 0.9169 - val_loss: 0.3674 - val_acc: 0.9223\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.3526 - acc: 0.9242 - val_loss: 0.3310 - val_acc: 0.9320\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.3134 - acc: 0.9291 - val_loss: 0.3004 - val_acc: 0.9320\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.2799 - acc: 0.9340 - val_loss: 0.2753 - val_acc: 0.9320\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.2521 - acc: 0.9389 - val_loss: 0.2563 - val_acc: 0.9320\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.2297 - acc: 0.9413 - val_loss: 0.2414 - val_acc: 0.9223\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.2117 - acc: 0.9413 - val_loss: 0.2295 - val_acc: 0.9223\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.4034 - acc: 0.8240 - val_loss: 0.3240 - val_acc: 0.8835\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.1774 - acc: 0.9584 - val_loss: 0.2152 - val_acc: 0.9126\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.1023 - acc: 0.9707 - val_loss: 0.2099 - val_acc: 0.9223\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.0799 - acc: 0.9780 - val_loss: 0.1833 - val_acc: 0.9320\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.0709 - acc: 0.9804 - val_loss: 0.1789 - val_acc: 0.9417\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.0657 - acc: 0.9804 - val_loss: 0.1759 - val_acc: 0.9417\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.0626 - acc: 0.9853 - val_loss: 0.1840 - val_acc: 0.9417\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.0595 - acc: 0.9853 - val_loss: 0.1787 - val_acc: 0.9417\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.0559 - acc: 0.9902 - val_loss: 0.1772 - val_acc: 0.9417\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.0535 - acc: 0.9878 - val_loss: 0.1841 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.0535 - acc: 0.9902 - val_loss: 0.1715 - val_acc: 0.9417\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.0494 - acc: 0.9878 - val_loss: 0.1910 - val_acc: 0.9417\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.0482 - acc: 0.9878 - val_loss: 0.1749 - val_acc: 0.9515\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.0476 - acc: 0.9927 - val_loss: 0.1843 - val_acc: 0.9417\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.0451 - acc: 0.9902 - val_loss: 0.1800 - val_acc: 0.9515\n",
      "added layer\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.7392 - acc: 0.3961 - val_loss: 0.7100 - val_acc: 0.4078\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.6846 - acc: 0.5159 - val_loss: 0.6578 - val_acc: 0.6602\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.6295 - acc: 0.8264 - val_loss: 0.6037 - val_acc: 0.8932\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.5721 - acc: 0.9364 - val_loss: 0.5458 - val_acc: 0.9126\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.5086 - acc: 0.9487 - val_loss: 0.4844 - val_acc: 0.9126\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.4411 - acc: 0.9560 - val_loss: 0.4181 - val_acc: 0.9126\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.3695 - acc: 0.9584 - val_loss: 0.3558 - val_acc: 0.9126\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.3048 - acc: 0.9584 - val_loss: 0.3045 - val_acc: 0.9223\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.2511 - acc: 0.9609 - val_loss: 0.2667 - val_acc: 0.9223\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.2119 - acc: 0.9633 - val_loss: 0.2399 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.1824 - acc: 0.9633 - val_loss: 0.2242 - val_acc: 0.9320\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.1618 - acc: 0.9682 - val_loss: 0.2132 - val_acc: 0.9320\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.1463 - acc: 0.9707 - val_loss: 0.2058 - val_acc: 0.9320\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.1346 - acc: 0.9707 - val_loss: 0.2006 - val_acc: 0.9320\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.1251 - acc: 0.9731 - val_loss: 0.1978 - val_acc: 0.9320\n",
      "added layer\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.5369 - acc: 0.6259 - val_loss: 0.4159 - val_acc: 0.6990\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.3218 - acc: 0.8900 - val_loss: 0.2774 - val_acc: 0.9320\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.1862 - acc: 0.9707 - val_loss: 0.1886 - val_acc: 0.9417\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.1223 - acc: 0.9731 - val_loss: 0.2107 - val_acc: 0.9223\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.0993 - acc: 0.9829 - val_loss: 0.1680 - val_acc: 0.9320\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.0888 - acc: 0.9878 - val_loss: 0.1553 - val_acc: 0.9417\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.0806 - acc: 0.9878 - val_loss: 0.1676 - val_acc: 0.9417\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.0781 - acc: 0.9829 - val_loss: 0.1613 - val_acc: 0.9417\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.0721 - acc: 0.9853 - val_loss: 0.1641 - val_acc: 0.9417\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.0705 - acc: 0.9853 - val_loss: 0.1662 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.0675 - acc: 0.9902 - val_loss: 0.1752 - val_acc: 0.9417\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.0697 - acc: 0.9853 - val_loss: 0.1820 - val_acc: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.0592 - acc: 0.9902 - val_loss: 0.1651 - val_acc: 0.9515\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.0603 - acc: 0.9878 - val_loss: 0.1712 - val_acc: 0.9515\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.0543 - acc: 0.9902 - val_loss: 0.1781 - val_acc: 0.9515\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.9200 - acc: 0.3105 - val_loss: 0.9130 - val_acc: 0.3107\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.8439 - acc: 0.4352 - val_loss: 0.8386 - val_acc: 0.4272\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.7758 - acc: 0.6064 - val_loss: 0.7726 - val_acc: 0.6214\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.7162 - acc: 0.7628 - val_loss: 0.7145 - val_acc: 0.7282\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.6627 - acc: 0.8362 - val_loss: 0.6635 - val_acc: 0.8058\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.6159 - acc: 0.8778 - val_loss: 0.6188 - val_acc: 0.8155\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.5729 - acc: 0.8924 - val_loss: 0.5794 - val_acc: 0.8350\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.5346 - acc: 0.9022 - val_loss: 0.5456 - val_acc: 0.8447\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.5006 - acc: 0.9071 - val_loss: 0.5161 - val_acc: 0.8641\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.4696 - acc: 0.9144 - val_loss: 0.4902 - val_acc: 0.8835\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.4425 - acc: 0.9267 - val_loss: 0.4669 - val_acc: 0.8932\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.4187 - acc: 0.9291 - val_loss: 0.4455 - val_acc: 0.9126\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.3970 - acc: 0.9340 - val_loss: 0.4267 - val_acc: 0.9126\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.3779 - acc: 0.9340 - val_loss: 0.4103 - val_acc: 0.9126\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.3613 - acc: 0.9389 - val_loss: 0.3952 - val_acc: 0.9126\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.3943 - acc: 0.9511 - val_loss: 0.2849 - val_acc: 0.9417\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.2263 - acc: 0.9707 - val_loss: 0.2254 - val_acc: 0.9417\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.1752 - acc: 0.9756 - val_loss: 0.2048 - val_acc: 0.9417\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.1440 - acc: 0.9804 - val_loss: 0.1868 - val_acc: 0.9417\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.1248 - acc: 0.9853 - val_loss: 0.1725 - val_acc: 0.9417\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.1122 - acc: 0.9853 - val_loss: 0.1630 - val_acc: 0.9417\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.1039 - acc: 0.9829 - val_loss: 0.1577 - val_acc: 0.9417\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.0968 - acc: 0.9829 - val_loss: 0.1529 - val_acc: 0.9417\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.0917 - acc: 0.9853 - val_loss: 0.1445 - val_acc: 0.9417\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.0881 - acc: 0.9829 - val_loss: 0.1454 - val_acc: 0.9320\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.0850 - acc: 0.9780 - val_loss: 0.1418 - val_acc: 0.9320\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.0827 - acc: 0.9853 - val_loss: 0.1350 - val_acc: 0.9417\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.0803 - acc: 0.9853 - val_loss: 0.1425 - val_acc: 0.9320\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.0790 - acc: 0.9780 - val_loss: 0.1357 - val_acc: 0.9417\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.0775 - acc: 0.9829 - val_loss: 0.1363 - val_acc: 0.9417\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.8758 - acc: 0.5941 - val_loss: 0.8270 - val_acc: 0.6990\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.8009 - acc: 0.7653 - val_loss: 0.7582 - val_acc: 0.8155\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.7315 - acc: 0.8704 - val_loss: 0.6983 - val_acc: 0.8447\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.6699 - acc: 0.8875 - val_loss: 0.6442 - val_acc: 0.9029\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.6127 - acc: 0.9120 - val_loss: 0.5949 - val_acc: 0.9126\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.5618 - acc: 0.9462 - val_loss: 0.5509 - val_acc: 0.9029\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.5159 - acc: 0.9560 - val_loss: 0.5124 - val_acc: 0.9029\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.4767 - acc: 0.9584 - val_loss: 0.4796 - val_acc: 0.9126\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.4430 - acc: 0.9609 - val_loss: 0.4521 - val_acc: 0.9029\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.4152 - acc: 0.9584 - val_loss: 0.4288 - val_acc: 0.9029\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.3917 - acc: 0.9609 - val_loss: 0.4101 - val_acc: 0.9029\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.3722 - acc: 0.9633 - val_loss: 0.3943 - val_acc: 0.9029\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.3555 - acc: 0.9633 - val_loss: 0.3815 - val_acc: 0.9126\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.3410 - acc: 0.9633 - val_loss: 0.3705 - val_acc: 0.9126\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.3286 - acc: 0.9682 - val_loss: 0.3605 - val_acc: 0.9126\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.5633 - acc: 0.8240 - val_loss: 0.4432 - val_acc: 0.9223\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.3397 - acc: 0.9658 - val_loss: 0.3172 - val_acc: 0.9320\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.2271 - acc: 0.9780 - val_loss: 0.2473 - val_acc: 0.9417\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.1740 - acc: 0.9829 - val_loss: 0.2180 - val_acc: 0.9320\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.1422 - acc: 0.9853 - val_loss: 0.2012 - val_acc: 0.9417\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.1249 - acc: 0.9853 - val_loss: 0.1807 - val_acc: 0.9417\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.1150 - acc: 0.9829 - val_loss: 0.1715 - val_acc: 0.9417\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.1075 - acc: 0.9853 - val_loss: 0.1677 - val_acc: 0.9417\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.1036 - acc: 0.9853 - val_loss: 0.1706 - val_acc: 0.9417\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.1000 - acc: 0.9829 - val_loss: 0.1594 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.0950 - acc: 0.9829 - val_loss: 0.1607 - val_acc: 0.9417\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.0927 - acc: 0.9853 - val_loss: 0.1518 - val_acc: 0.9515\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.0900 - acc: 0.9829 - val_loss: 0.1458 - val_acc: 0.9515\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.0898 - acc: 0.9829 - val_loss: 0.1478 - val_acc: 0.9417\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.0887 - acc: 0.9804 - val_loss: 0.1468 - val_acc: 0.9417\n",
      "added layer\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.9489 - acc: 0.6797 - val_loss: 0.8990 - val_acc: 0.7864\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.8737 - acc: 0.8680 - val_loss: 0.8323 - val_acc: 0.8738\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.8021 - acc: 0.8924 - val_loss: 0.7718 - val_acc: 0.8738\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.7374 - acc: 0.9071 - val_loss: 0.7156 - val_acc: 0.8641\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.6769 - acc: 0.9144 - val_loss: 0.6682 - val_acc: 0.8738\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.6244 - acc: 0.9193 - val_loss: 0.6246 - val_acc: 0.8932\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.5780 - acc: 0.9218 - val_loss: 0.5874 - val_acc: 0.9029\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.5406 - acc: 0.9267 - val_loss: 0.5555 - val_acc: 0.9029\n",
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.5086 - acc: 0.9267 - val_loss: 0.5266 - val_acc: 0.9029\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.4829 - acc: 0.9291 - val_loss: 0.5045 - val_acc: 0.9029\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.4591 - acc: 0.9291 - val_loss: 0.4842 - val_acc: 0.9126\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.4384 - acc: 0.9315 - val_loss: 0.4640 - val_acc: 0.9223\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.4187 - acc: 0.9340 - val_loss: 0.4452 - val_acc: 0.9320\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.4004 - acc: 0.9462 - val_loss: 0.4299 - val_acc: 0.9320\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.3849 - acc: 0.9535 - val_loss: 0.4161 - val_acc: 0.9223\n",
      "added layer\n",
      "added layer\n",
      "added layer\n",
      "Train on 409 samples, validate on 103 samples\n",
      "Epoch 1/15\n",
      "409/409 - 2s - loss: 0.6726 - acc: 0.9535 - val_loss: 0.4701 - val_acc: 0.9320\n",
      "Epoch 2/15\n",
      "409/409 - 0s - loss: 0.3553 - acc: 0.9584 - val_loss: 0.3902 - val_acc: 0.9320\n",
      "Epoch 3/15\n",
      "409/409 - 0s - loss: 0.2603 - acc: 0.9780 - val_loss: 0.3098 - val_acc: 0.9320\n",
      "Epoch 4/15\n",
      "409/409 - 0s - loss: 0.2071 - acc: 0.9829 - val_loss: 0.2711 - val_acc: 0.9417\n",
      "Epoch 5/15\n",
      "409/409 - 0s - loss: 0.1750 - acc: 0.9829 - val_loss: 0.2420 - val_acc: 0.9417\n",
      "Epoch 6/15\n",
      "409/409 - 0s - loss: 0.1534 - acc: 0.9829 - val_loss: 0.2170 - val_acc: 0.9417\n",
      "Epoch 7/15\n",
      "409/409 - 0s - loss: 0.1389 - acc: 0.9829 - val_loss: 0.2135 - val_acc: 0.9417\n",
      "Epoch 8/15\n",
      "409/409 - 0s - loss: 0.1305 - acc: 0.9780 - val_loss: 0.1887 - val_acc: 0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "409/409 - 0s - loss: 0.1287 - acc: 0.9853 - val_loss: 0.2114 - val_acc: 0.9320\n",
      "Epoch 10/15\n",
      "409/409 - 0s - loss: 0.1212 - acc: 0.9853 - val_loss: 0.1800 - val_acc: 0.9417\n",
      "Epoch 11/15\n",
      "409/409 - 0s - loss: 0.1176 - acc: 0.9829 - val_loss: 0.2126 - val_acc: 0.9320\n",
      "Epoch 12/15\n",
      "409/409 - 0s - loss: 0.1242 - acc: 0.9756 - val_loss: 0.1644 - val_acc: 0.9417\n",
      "Epoch 13/15\n",
      "409/409 - 0s - loss: 0.1185 - acc: 0.9804 - val_loss: 0.1869 - val_acc: 0.9320\n",
      "Epoch 14/15\n",
      "409/409 - 0s - loss: 0.1200 - acc: 0.9804 - val_loss: 0.2075 - val_acc: 0.9320\n",
      "Epoch 15/15\n",
      "409/409 - 0s - loss: 0.1198 - acc: 0.9756 - val_loss: 0.1649 - val_acc: 0.9417\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "seed(42)\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['diagnosis_num'] = le.fit_transform(df['diagnosis'])\n",
    "\n",
    "X = df[top_10_features]\n",
    "y = df['diagnosis_num'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "for regular in [0.001,0.01]:\n",
    "    for n_layers in [1,2,3]:\n",
    "        for rate in [0.001,0.01]:\n",
    "            model = Sequential() #means we can add layers one at a time\n",
    "            \n",
    "            model_name = f\"reg={regular}-n_layers={n_layers}-lr={rate}\"\n",
    "            tensorboard = TensorBoard(log_dir=f\"model_logs\\\\{model_name}\")\n",
    "            \n",
    "            regularizer = regularizers.l2(regular)\n",
    "            for i in range(0,n_layers):\n",
    "                print('added layer')\n",
    "                model.add(Dense(10,activation='relu',kernel_regularizer=regularizer))\n",
    "            \n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "                \n",
    "            new_optimizer = optimizers.Adam(lr=rate) #lets change the learning rate\n",
    "            model.compile(optimizer=new_optimizer, loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "            \n",
    "            model.fit(X_train, y_train, epochs=15, validation_split=0.2, callbacks=[tensorboard], verbose=2)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
